import streamlit as st
import pandas as pd
import time
import difflib
import plotly.express as px
from openai import OpenAI

# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¸íŒ…
st.set_page_config(page_title="Deep Agora: ê°€ì¹˜ì˜ ìˆ²", layout="wide", page_icon="ğŸŒ²")

# --- [ìŠ¤íƒ€ì¼] CSS ì»¤ìŠ¤í…€ (Dark Forest Theme) ---
st.markdown("""
<style>
    /* ì „ì²´ ë°°ê²½ */
    .stApp { background-color: #0E1117; }
    
    /* í…ìŠ¤íŠ¸ ê°€ë…ì„± */
    .stMarkdown, .stText, p, div, span, label, li {
        color: #C1C7D0 !important;
        font-family: 'Pretendard', sans-serif;
        font-weight: 400 !important;
    }
    
    /* í—¤ë” í¬ì¸íŠ¸ */
    h1, h2, h3 { color: #69F0AE !important; }

    /* ë‰´ìŠ¤ ì¹´ë“œ */
    .news-card {
        background-color: #161B22;
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #2196F3;
        margin-bottom: 20px;
        color: #C9D1D9;
    }
    
    /* ì…ë ¥ì°½ ì»¤ìŠ¤í…€ */
    .stTextInput > div > div > input {
        background-color: #21262D !important;
        color: white !important;
        border: 1px solid #30363D;
    }
    
    /* ìŠ¬ë¼ì´ë” ìŠ¤íƒ€ì¼ */
    .stSlider > div > div > div > div {
        background-color: #69F0AE;
    }
</style>
""", unsafe_allow_html=True)

# --- [ë³´ì•ˆ] API í‚¤ ë¡œë“œ ---
if "OPENAI_API_KEY" in st.secrets:
    api_key = st.secrets["OPENAI_API_KEY"]
else:
    st.error("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

# --- 0. ì´ˆê¸° ë°ì´í„° (ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ í¬í•¨) ---
should_reset = False
if "forest_df" not in st.session_state:
    should_reset = True
else:
    if "full_text" not in st.session_state.forest_df.columns:
        should_reset = True

if should_reset:
    data = {
        "refined_text": [
            "ìš°íšŒ ê¸°ìˆ  ë³´í¸í™”ë¡œ ì‹¤íš¨ì„± ìš°ë ¤",
            "ì²­ì†Œë…„ ë³´í˜¸ë¥¼ ìœ„í•œ êµ­ê°€ ê·œì œ í•„ìš”",
            "ë¯¸ë””ì–´ ë¦¬í„°ëŸ¬ì‹œ êµìœ¡ì´ ê·¼ë³¸ ëŒ€ì•ˆ",
            "ì•Œê³ ë¦¬ì¦˜ ì¤‘ë… ê¸°ì—… ì±…ì„ ê°•í™”",
            "ì—°ë ¹ ì¸ì¦ ì‹œ ê°œì¸ì •ë³´ ì¹¨í•´ ìš°ë ¤",
        ],
        "full_text": [ 
            "ìš°íšŒ ê¸°ìˆ ì´ ë³´í¸í™”ëœ ìƒí™©ì—ì„œ ë‹¨ìˆœ ì°¨ë‹¨ì€ ì‹¤íš¨ì„±ì´ ë‚®ë‹¤ëŠ” ê¸°ìˆ ì  ìš°ë ¤ê°€ ìˆìŠµë‹ˆë‹¤.",
            "ì²­ì†Œë…„ì˜ ì •ì‹ ê±´ê°• ë³´í˜¸ë¥¼ ìœ„í•´ êµ­ê°€ ì°¨ì›ì˜ ê·œì œê°€ í•„ìš”í•˜ë‹¤ëŠ” ì ì— ê³µê°í•©ë‹ˆë‹¤.",
            "ê¸°ìˆ ì  ì°¨ë‹¨ë³´ë‹¤ëŠ” ë¯¸ë””ì–´ ë¦¬í„°ëŸ¬ì‹œ êµìœ¡ì´ ê·¼ë³¸ì ì¸ í•´ê²°ì±…ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "ì¤‘ë…ì„± ê°•í•œ ì•Œê³ ë¦¬ì¦˜ì„ ë°©ì¹˜í•œ ê¸°ì—…ì˜ ì‚¬íšŒì  ì±…ì„ì„ ê°•í™”í•´ì•¼ í•©ë‹ˆë‹¤.",
            "ì—°ë ¹ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ ë“±ì„ ìš”êµ¬í•˜ëŠ” ê²ƒì€ ê³¼ë„í•œ ê°œì¸ì •ë³´ ìˆ˜ì§‘ì…ë‹ˆë‹¤."
        ],
        "keyword": [
            "ê¸°ìˆ ì  ì‹¤íš¨ì„±", "ì²­ì†Œë…„ ë³´í˜¸", "ëŒ€ì•ˆì  êµìœ¡", "ê¸°ì—…ì˜ ì±…ì„", "í”„ë¼ì´ë²„ì‹œ"
        ],
        "count": [15, 12, 8, 6, 10]
    }
    st.session_state.forest_df = pd.DataFrame(data)

# --- [ìˆ˜ì •ëœ í•µì‹¬ ë¡œì§] GPT í”„ë¡¬í”„íŠ¸ (Topic Guard ê°œì„ ) ---
def process_opinion_with_gpt(user_text, purity_level):
    client = OpenAI(api_key=api_key)
    existing_keywords = ", ".join(st.session_state.forest_df['keyword'].unique())
    
    if purity_level >= 80:
        tone_instruction = "Extremely formal, diplomatic, and soft tone."
    elif purity_level >= 40:
        tone_instruction = "Polite, objective, and declarative tone."
    else:
        tone_instruction = "Direct and assertive tone. Remove only curse words."

    # [í”„ë¡¬í”„íŠ¸ ìˆ˜ì • í¬ì¸íŠ¸]
    # 1. Relevance Checkì— 'VPN', 'Bypass', 'Education' ë“± êµ¬ì²´ì  í‚¤ì›Œë“œ ëª…ì‹œ
    # 2. "Casual tone is OK"ë¼ê³  ëª…ì‹œí•˜ì—¬ ë§íˆ¬ ë•Œë¬¸ì— ê±°ì ˆí•˜ì§€ ì•Šë„ë¡ í•¨
    system_prompt = f"""
    You are a 'Civic Editor' acting as a Gatekeeper.
    
    [Step 1: Relevance Check]
    Check if the user input is logically related to: 
    - "Australia's SNS ban for under-16s"
    - "Social Media Regulation / Teenager Protection"
    - "Technical Feasibility (e.g., VPN, Bypass, Verification errors)"
    - "Digital Rights / Privacy"
    
    * CRITICAL: Even if the user uses slang, informal language, or short sentences (e.g., "VPN ì“°ë©´ ë¨", "ì´ê²Œ ë§ì´ ë˜ëƒ"), IF the meaning is relevant, proceed to Step 2.
    * REJECT ONLY IF: The input is about South Korean domestic politics (President Yoon, impeachment), Sports, Food, or meaningless gibberish.
      -> In that case, OUTPUT ONLY: "REJECT"
    
    [Step 2: Processing]
    1. REWRITE input into Korean ({tone_instruction}).
    2. EXTRACT 'Value Keyword' (Noun, max 3 words).
    3. Create 'Short Label' (max 20 chars).
    
    Format: Keyword|Short Label|Full Refined Text
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_text}],
            temperature=0.3
        )
        result = response.choices[0].message.content
        
        if "REJECT" in result:
            return "REJECT"
            
        keyword, short_label, full_text = result.split("|", 2)
        return {
            "keyword": keyword.strip(),
            "short_label": short_label.strip(),
            "full_text": full_text.strip()
        }
    except:
        return None

# --- [ë¡œì§] ìœ ì‚¬ë„ ë³‘í•© ---
def merge_opinion(new_full_text, keyword, df):
    subset = df[df['keyword'] == keyword]
    for idx, row in subset.iterrows():
        similarity = difflib.SequenceMatcher(None, new_full_text, row['full_text']).ratio()
        if similarity >= 0.7: 
            return idx, True 
    return None, False

# ================= UI ì‹œì‘ =================

st.title("ğŸŒ² Deep Agora: ê°€ì¹˜ì˜ ìˆ²")

# 1. ë‰´ìŠ¤ ë¸Œë¦¬í•‘
st.markdown("""
<div class="news-card">
    <h4>ğŸ“¢ [ì´ìŠˆ] í˜¸ì£¼, 16ì„¸ ë¯¸ë§Œ SNS ì›ì²œ ì°¨ë‹¨ ë²•ì•ˆ</h4>
    <p>í˜¸ì£¼ ì •ë¶€ê°€ ì²­ì†Œë…„ ì •ì‹ ê±´ê°• ë³´í˜¸ë¥¼ ìœ„í•´ SNS ê³„ì • ë³´ìœ ë¥¼ ê¸ˆì§€í•©ë‹ˆë‹¤.<br>
    ìŸì : <b>êµ­ê°€ì˜ ë³´í˜¸ ì˜ë¬´</b> vs <b>ê¸°ìˆ ì  ì‹¤íš¨ì„± ë° ê¸°ë³¸ê¶Œ</b></p>
</div>
""", unsafe_allow_html=True)
st.link_button("ğŸ”— ê´€ë ¨ ê¸°ì‚¬ ì›ë¬¸ ë³´ê¸° (ì—°í•©ë‰´ìŠ¤)", "https://www.yna.co.kr/view/AKR20251209006700084?input=1195m")

st.divider()

# 2. ì˜ê²¬ ì‹¬ê¸°
st.markdown("#### ğŸ‘©â€ğŸŒ¾ ë‹¹ì‹ ì˜ ì˜ê²¬ì„ ì‹¬ì–´ì£¼ì„¸ìš”")
col_input, col_opt = st.columns([3, 1])

with col_input:
    user_input = st.text_input("ìƒê° ì…ë ¥", label_visibility="collapsed", placeholder="ì˜ˆ: ë¬´ì¡°ê±´ ë§‰ëŠ” ê±´ ë‹µì´ ì•„ë‹™ë‹ˆë‹¤. êµìœ¡ì´ ë¨¼ì €ì£ .")

with col_opt:
    purity = st.slider("ì •ì œ ê°•ë„", 0, 100, 70, help="ë‚®ì„ìˆ˜ë¡ ì§ì„¤ì , ë†’ì„ìˆ˜ë¡ ì™„ê³¡í•˜ê²Œ í‘œí˜„ë©ë‹ˆë‹¤.")
    submit = st.button("ìˆ²ì— ì‹¬ê¸° ğŸŒ±", type="primary", use_container_width=True)

if submit and user_input:
    with st.spinner("AIê°€ ì˜ê²¬ì„ ê²€í† í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        res = process_opinion_with_gpt(user_input, purity)
        
        # [ìˆ˜ì •] ê²°ê³¼ ì²˜ë¦¬ ë¡œì§ ë¶„ê¸°
        if res == "REJECT":
            st.error("ğŸš« ì£¼ì œì™€ ë¬´ê´€í•œ ì˜ê²¬(êµ­ë‚´ ì •ì¹˜, ë¹„ë°©, ì¡ë‹´ ë“±)ì€ ì •ì›ì— ì‹¬ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        elif res:
            idx, merged = merge_opinion(res['full_text'], res['keyword'], st.session_state.forest_df)
            
            if merged:
                st.session_state.forest_df.at[idx, 'count'] += 1
                msg = f"'{res['keyword']}' ë‚˜ë¬´ê°€ ë” í¬ê²Œ ìëìŠµë‹ˆë‹¤! (ê³µê° +1) ğŸ’§"
            else:
                new_row = {
                    "refined_text": res['short_label'],
                    "full_text": res['full_text'],
                    "keyword": res['keyword'],
                    "count": 1
                }
                st.session_state.forest_df = pd.concat([pd.DataFrame([new_row]), st.session_state.forest_df], ignore_index=True)
                msg = f"ìƒˆë¡œìš´ ë¬˜ëª© '{res['keyword']}'ì„ ì‹¬ì—ˆìŠµë‹ˆë‹¤! ğŸŒ²"
            
            st.success(msg)
            time.sleep(1.0)
            st.rerun()
        else:
            st.error("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

st.divider()

# 3. ê°€ì¹˜ì˜ ìˆ² ì‹œê°í™”
st.subheader("ğŸŒ³ ê°€ì¹˜ì˜ ì§€ë„ (Value Map)")

if not st.session_state.forest_df.empty:
    df = st.session_state.forest_df
    
    fig = px.treemap(
        df, 
        path=[px.Constant("Deep Agora"), 'keyword', 'refined_text'],
        values='count',
        color='keyword',
        color_discrete_sequence=px.colors.qualitative.Set3,
        custom_data=['full_text', 'count']
    )
    
    fig.update_layout(
        margin=dict(t=0, l=0, r=0, b=0),
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(family="Pretendard", color='#E0E0E0'),
        uniformtext=dict(minsize=14, mode='hide')
    )
    
    fig.update_traces(
        root_color="#1E2329",
        textinfo="label+value",
        hovertemplate='<b>%{label}</b><br><br>ğŸ“ ì „ì²´ ì˜ê²¬:<br>%{customdata[0]}<br><br>ğŸ’§ ê³µê°: %{customdata[1]}<extra></extra>',
        marker=dict(cornerradius=5)
    )
    
    st.plotly_chart(fig, use_container_width=True)

    with st.expander("ğŸ“œ ì˜ê²¬ ëª©ë¡ ìì„¸íˆ ë³´ê¸°"):
        st.dataframe(
            df[['keyword', 'full_text', 'count']].sort_values(by='count', ascending=False),
            column_config={
                "keyword": "í•µì‹¬ ê°€ì¹˜",
                "full_text": "ì „ì²´ ì˜ê²¬",
                "count": st.column_config.NumberColumn("ê³µê°", format="ğŸ’§ %d")
            },
            hide_index=True,
            use_container_width=True
        )
else:
    st.info("ì•„ì§ ìˆ²ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì˜ê²¬ì„ ì‹¬ì–´ì£¼ì„¸ìš”!")
